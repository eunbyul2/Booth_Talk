# services/llm_service.py
"""
LLM API ì—°ë™ ì„œë¹„ìŠ¤ - ì´ë²¤íŠ¸ í¼ ìë™ ì™„ì„± + íƒœê·¸ ìƒì„±
"""

import os
from typing import Optional, Dict, Any, List
import openai
import anthropic
from dotenv import load_dotenv
import json

load_dotenv()


class LLMService:
    """LLM API í†µí•© ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.openai_client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.anthropic_client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        self.default_provider = os.getenv("LLM_PROVIDER", "openai")
    
    
    async def analyze_and_fill_event_form(
        self, 
        image_url: str,
        provider: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ì´ë²¤íŠ¸ ì´ë¯¸ì§€ ë¶„ì„ â†’ í¼ ìë™ ì™„ì„± + íƒœê·¸ ìƒì„±
        
        Args:
            image_url: ë¶„ì„í•  ì´ë¯¸ì§€ URL (í¬ìŠ¤í„°, ì „ë‹¨ì§€ ë“±)
            provider: LLM ì œê³µì (openai/anthropic)
            
        Returns:
            dict: {
                "form_data": {
                    "eventName": "ì´ë²¤íŠ¸ ì œëª©",
                    "boothNumber": "ë¶€ìŠ¤ ë²ˆí˜¸",
                    "date": "ë‚ ì§œ",
                    "time": "ì‹œê°„",
                    "description": "ì„¤ëª…",
                    "participationMethod": "ì°¸ì—¬ ë°©ë²•",
                    "benefits": "í˜œíƒ"
                },
                "tags": ["íƒœê·¸1", "íƒœê·¸2", ...],
                "categories": ["ì¹´í…Œê³ ë¦¬1", "ì¹´í…Œê³ ë¦¬2"],
                "confidence": 0.95
            }
        """
        provider = provider or self.default_provider
        
        prompt = """
ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì´ë²¤íŠ¸/ì „ì‹œíšŒ/ë°•ëŒíšŒ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ì´ë²¤íŠ¸ ìœ í˜•ì— ê´€ê³„ì—†ì´ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.

ğŸ¯ ë¶„ì„ ê°€ì´ë“œ:
1. ì´ë²¤íŠ¸ ìœ í˜•ì„ ë¨¼ì € íŒŒì•…í•˜ì„¸ìš” (ì „ì‹œíšŒ/ë°•ëŒíšŒ/ì»¨í¼ëŸ°ìŠ¤/ì„¸ë¯¸ë‚˜/ê³µì—°/ì²´í—˜í–‰ì‚¬ ë“±)
2. ê° ìœ í˜•ì— ë§ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”
3. í•œêµ­ì–´ì™€ ì˜ì–´ê°€ í˜¼ì¬ë˜ì–´ ìˆì–´ë„ ëª¨ë‘ ì¸ì‹í•˜ì„¸ìš”
4. ë‚ ì§œ/ì‹œê°„ì€ ë°˜ë“œì‹œ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”

ğŸ“… ë‚ ì§œ ë³€í™˜ ê·œì¹™:
- ëª¨ë“  ë‚ ì§œ â†’ YYYY-MM-DD í˜•ì‹
- ì˜ˆ: "12ì›” 15ì¼" â†’ startDate: "2024-12-15", endDate: "2024-12-15"
- ê¸°ê°„: "12/15-12/17" â†’ startDate: "2024-12-15", endDate: "2024-12-17"
- ë‹¨ì¼ ë‚ ì§œì¸ ê²½ìš° ì‹œì‘ê³¼ ì¢…ë£Œ ë‚ ì§œë¥¼ ë™ì¼í•˜ê²Œ ì„¤ì •

ğŸ•’ ì‹œê°„ ë³€í™˜ ê·œì¹™:
- 24ì‹œê°„ í˜•ì‹ìœ¼ë¡œ í†µì¼: "ì˜¤í›„ 2ì‹œ" â†’ startTime: "14:00", endTime: ""
- ë²”ìœ„: "ì˜¤ì „ 9ì‹œ-ì˜¤í›„ 6ì‹œ" â†’ startTime: "09:00", endTime: "18:00"
- AM/PM ì²˜ë¦¬: "9 AM - 6 PM" â†’ startTime: "09:00", endTime: "18:00"
- ë‹¨ì¼ ì‹œê°„ì¸ ê²½ìš° endTimeì€ ë¹ˆ ë¬¸ìì—´
- ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›:
  * "AM 9:00 ~ PM 6:00" â†’ startTime: "09:00", endTime: "18:00"
  * "9am-6pm" â†’ startTime: "09:00", endTime: "18:00"
  * "ì˜¤ì „ 10ì‹œ 30ë¶„ - ì˜¤í›„ 5ì‹œ" â†’ startTime: "10:30", endTime: "17:00"
  * "Morning 9:30" â†’ startTime: "09:30", endTime: ""

ğŸ“ ì¥ì†Œ ì¶”ì¶œ ê°€ì´ë“œ:
- location: ë©”ì¸ ì¥ì†Œëª… (ì½”ì—‘ìŠ¤, í‚¨í…ìŠ¤, ì„œìš¸ì—­ ë“±)
- venue: ì„¸ë¶€ ìœ„ì¹˜ (1ì¸µ Aí™€, ì»¨í¼ëŸ°ìŠ¤ë£¸, ì•¼ì™¸ë¬´ëŒ€ ë“±)
- boothNumber: ë¶€ìŠ¤/ì¢Œì„ ë²ˆí˜¸

ğŸ·ï¸ ìŠ¤ë§ˆíŠ¸ íƒœê·¸ ìƒì„±:
ì´ë²¤íŠ¸ ìœ í˜•ê³¼ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ì— ìœ ìš©í•œ íƒœê·¸ë¥¼ ìë™ ìƒì„±í•˜ì„¸ìš”.
- ì „ì‹œíšŒ: "ì‘í’ˆê°ìƒ", "ì‚¬ì§„ì´¬ì˜ê°€ëŠ¥", "ë„ë¡íŒë§¤"
- ë°•ëŒíšŒ: "ì²´í—˜ê°€ëŠ¥", "ìƒë‹´ê°€ëŠ¥", "ì‹ ì œí’ˆ"
- ì»¨í¼ëŸ°ìŠ¤: "ì „ë¬¸ê°€ê°•ì—°", "ë„¤íŠ¸ì›Œí‚¹", "ìë£Œì œê³µ"
- ê³µì—°: "ì¢Œì„ì˜ˆì•½", "ë“œë ˆìŠ¤ì½”ë“œ", "ê³µì—°ì‹œê°„"
- ì²´í—˜í–‰ì‚¬: "ì°¸ì—¬í˜•", "ê°€ì¡±í™˜ì˜", "ì¬ë£Œì œê³µ"

{
    "form_data": {
        "eventName": "ì •í™•í•œ ì´ë²¤íŠ¸ëª…",
        "boothNumber": "ë¶€ìŠ¤ë²ˆí˜¸",
        "location": "ë„ì‹œ/ì§€ì—­ëª…", 
        "venue": "ìƒì„¸ ì¥ì†Œëª…",
        "startDate": "YYYY-MM-DD (ì‹œì‘ ë‚ ì§œ)",
        "endDate": "YYYY-MM-DD (ì¢…ë£Œ ë‚ ì§œ, ë‹¨ì¼ ë‚ ì§œì¸ ê²½ìš° ì‹œì‘ ë‚ ì§œì™€ ë™ì¼)",
        "startTime": "HH:MM (ì‹œì‘ ì‹œê°„, 24ì‹œê°„ì œ)",
        "endTime": "HH:MM (ì¢…ë£Œ ì‹œê°„, 24ì‹œê°„ì œ)",
        "description": "ì´ë²¤íŠ¸ í•µì‹¬ ë‚´ìš© (150ì ì´ë‚´)",
        "participationMethod": "ì°¸ì—¬ ë°©ë²•",
        "benefits": "í˜œíƒ/ì œê³µì‚¬í•­"
    },
    "tags": [
        "ì´ë²¤íŠ¸ ìœ í˜•ê³¼ íŠ¹ì„±ì— ë§ëŠ” ê²€ìƒ‰ìš© íƒœê·¸ 5-8ê°œ"
    ],
    "categories": [
        "ì´ë²¤íŠ¸ ì¹´í…Œê³ ë¦¬ 1-3ê°œ (ìë™ ë¶„ë¥˜)"
    ],
    "target_audience": [
        "ëŒ€ìƒ ê´€ëŒê°"
    ],
    "atmosphere": [
        "ì´ë²¤íŠ¸ ë¶„ìœ„ê¸°"
    ]
}

âš ï¸ ì¤‘ìš”: ì´ë¯¸ì§€ì— ì—†ëŠ” ì •ë³´ëŠ” ë¹ˆ ë¬¸ìì—´ ""ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”.
"""
        
        if provider == "openai":
            result = await self._analyze_with_openai(image_url, prompt)
        else:
            result = await self._analyze_with_claude(image_url, prompt)
        
        # ì‹ ë¢°ë„ ì¶”ê°€ (LLM ì‘ë‹µì˜ ì™„ì„±ë„ í‰ê°€)
        result["confidence"] = self._calculate_confidence(result.get("form_data", {}))
        
        return result
    
    
    async def _analyze_with_openai(self, image_url: str, prompt: str) -> Dict[str, Any]:
        """OpenAI GPT-4 Visionìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„"""
        
        # ë¡œì»¬ íŒŒì¼ì¸ì§€ URLì¸ì§€ í™•ì¸
        if image_url.startswith(("http://", "https://")):
            # URLì¸ ê²½ìš°
            image_input = {
                "type": "image_url",
                "image_url": {"url": image_url}
            }
        else:
            # ë¡œì»¬ íŒŒì¼ì¸ ê²½ìš° base64ë¡œ ì¸ì½”ë”©
            import base64
            
            try:
                with open(image_url, "rb") as image_file:
                    image_data = image_file.read()
                    image_base64 = base64.b64encode(image_data).decode()
                    
                # íŒŒì¼ í™•ì¥ìë¡œ MIME íƒ€ì… ê²°ì •
                import mimetypes
                mime_type, _ = mimetypes.guess_type(image_url)
                if not mime_type or not mime_type.startswith('image/'):
                    mime_type = 'image/jpeg'  # ê¸°ë³¸ê°’
                
                image_input = {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{mime_type};base64,{image_base64}"
                    }
                }
            except Exception as e:
                raise ValueError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o",  # ìµœì‹  GPT-4o ëª¨ë¸ ì‚¬ìš©
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        image_input
                    ]
                }
            ],
            max_tokens=1500,
            temperature=0.2  # ì •í™•ì„±ì„ ìœ„í•´ ë‚®ê²Œ ì„¤ì •
        )
        
        result_text = response.choices[0].message.content
        
        # JSON íŒŒì‹±
        try:
            if "```json" in result_text:
                json_str = result_text.split("```json")[1].split("```")[0].strip()
            else:
                json_str = result_text
            
            result = json.loads(json_str)
            return result
        except Exception as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {
                "form_data": {},
                "tags": [],
                "categories": [],
                "error": str(e),
                "raw_response": result_text
            }
    
    
    async def _analyze_with_claude(self, image_url: str, prompt: str) -> Dict[str, Any]:
        """Anthropic Claude Visionìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„"""
        
        import requests
        import base64
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜
        image_data = requests.get(image_url).content
        image_base64 = base64.b64encode(image_data).decode()
        
        message = self.anthropic_client.messages.create(
            model="claude-3-opus-20240229",
            max_tokens=1500,
            temperature=0.2,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/jpeg",
                                "data": image_base64,
                            },
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ],
                }
            ],
        )
        
        result_text = message.content[0].text
        
        # JSON íŒŒì‹±
        try:
            if "```json" in result_text:
                json_str = result_text.split("```json")[1].split("```")[0].strip()
            else:
                json_str = result_text
            
            result = json.loads(json_str)
            return result
        except Exception as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {
                "form_data": {},
                "tags": [],
                "categories": [],
                "error": str(e),
                "raw_response": result_text
            }
    
    
    def _calculate_confidence(self, form_data: Dict) -> float:
        """
        í¼ ë°ì´í„°ì˜ ì™„ì„±ë„ í‰ê°€ (0.0 ~ 1.0)
        """
        required_fields = ["eventName", "date", "description"]
        optional_fields = ["boothNumber", "time", "participationMethod", "benefits"]
        
        filled_required = sum(1 for field in required_fields if form_data.get(field))
        filled_optional = sum(1 for field in optional_fields if form_data.get(field))
        
        # í•„ìˆ˜ í•„ë“œ 80%, ì„ íƒ í•„ë“œ 20%
        required_score = (filled_required / len(required_fields)) * 0.8
        optional_score = (filled_optional / len(optional_fields)) * 0.2
        
        return round(required_score + optional_score, 2)
    
    
    async def enhance_description(
        self,
        original_description: str,
        event_name: str,
        provider: Optional[str] = None
    ) -> str:
        """
        ì´ë²¤íŠ¸ ì„¤ëª… ê°œì„  (ì‚¬ìš©ìê°€ ìˆ˜ë™ ì…ë ¥í•œ ê²½ìš°)
        
        Args:
            original_description: ì›ë³¸ ì„¤ëª…
            event_name: ì´ë²¤íŠ¸ ì´ë¦„
            provider: LLM ì œê³µì
            
        Returns:
            str: ê°œì„ ëœ ì„¤ëª…
        """
        provider = provider or self.default_provider
        
        prompt = f"""
ë‹¤ìŒ ì´ë²¤íŠ¸ ì„¤ëª…ì„ ë” ë§¤ë ¥ì ì´ê³  ì „ë¬¸ì ìœ¼ë¡œ ê°œì„ í•´ì£¼ì„¸ìš”:

ì´ë²¤íŠ¸ëª…: {event_name}
í˜„ì¬ ì„¤ëª…: {original_description}

ìš”êµ¬ì‚¬í•­:
- 2-3ë¬¸ë‹¨, 150-200ì
- ë°©ë¬¸ê°ì—ê²Œ í¥ë¯¸ ìœ ë°œ
- ì „ë¬¸ì ì´ë©´ì„œ ì¹œê·¼í•œ í†¤
- í•µì‹¬ ë‚´ìš© ê°•ì¡°
"""
        
        if provider == "openai":
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.7
            )
            return response.choices[0].message.content
        else:
            message = self.anthropic_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=500,
                temperature=0.7,
                messages=[{"role": "user", "content": prompt}]
            )
            return message.content[0].text
    
    
    async def generate_additional_tags(
        self,
        form_data: Dict[str, str],
        existing_tags: List[str],
        provider: Optional[str] = None
    ) -> List[str]:
        """
        í¼ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ íƒœê·¸ ìƒì„±
        
        Args:
            form_data: ì´ë²¤íŠ¸ í¼ ë°ì´í„°
            existing_tags: ê¸°ì¡´ íƒœê·¸ ëª©ë¡
            provider: LLM ì œê³µì
            
        Returns:
            list: ì¶”ê°€ íƒœê·¸ (ì¤‘ë³µ ì œê±°)
        """
        provider = provider or self.default_provider
        
        prompt = f"""
ë‹¤ìŒ ì´ë²¤íŠ¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ê³¼ í•„í„°ë§ì— ìœ ìš©í•œ íƒœê·¸ë¥¼ 5-10ê°œ ìƒì„±í•´ì£¼ì„¸ìš”:

ì´ë²¤íŠ¸ëª…: {form_data.get('eventName', '')}
ì„¤ëª…: {form_data.get('description', '')}
ì°¸ì—¬ ë°©ë²•: {form_data.get('participationMethod', '')}
í˜œíƒ: {form_data.get('benefits', '')}

ê¸°ì¡´ íƒœê·¸: {', '.join(existing_tags)}

ìƒˆë¡œìš´ íƒœê·¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ:
- íŠ¹ì§•: ë¬´ë£Œê´€ëŒ, ì‚¬ì „ì˜ˆì•½í•„ìˆ˜, í˜„ì¥ë“±ë¡ê°€ëŠ¥
- í¸ì˜: ì£¼ì°¨ê°€ëŠ¥, ëŒ€ì¤‘êµí†µì ‘ê·¼ì„±, íœ ì²´ì–´ì ‘ê·¼ê°€ëŠ¥
- ëŒ€ìƒ: ì–´ë¦°ì´í™˜ì˜, ê°€ì¡±ë‹¨ìœ„, ì „ë¬¸ê°€ì¶”ì²œ
- ì²´í—˜: ì‚¬ì§„ì´¬ì˜ê°€ëŠ¥, ì²´í—˜í”„ë¡œê·¸ë¨, ì¸í„°ë™í‹°ë¸Œ
- ë¶„ìœ„ê¸°: ì¡°ìš©í•œë¶„ìœ„ê¸°, í™œê¸°ì°¬, êµìœ¡ì ì¸

JSON ë°°ì—´ë¡œë§Œ ë°˜í™˜: ["íƒœê·¸1", "íƒœê·¸2", ...]
"""
        
        if provider == "openai":
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.5
            )
            result_text = response.choices[0].message.content
        else:
            message = self.anthropic_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=300,
                temperature=0.5,
                messages=[{"role": "user", "content": prompt}]
            )
            result_text = message.content[0].text
        
        # JSON íŒŒì‹±
        try:
            if "```json" in result_text:
                json_str = result_text.split("```json")[1].split("```")[0].strip()
            elif "[" in result_text:
                # ë°°ì—´ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                json_str = result_text[result_text.find("["):result_text.rfind("]")+1]
            else:
                json_str = result_text
            
            new_tags = json.loads(json_str)
            
            # ê¸°ì¡´ íƒœê·¸ì™€ ì¤‘ë³µ ì œê±°
            unique_tags = [tag for tag in new_tags if tag not in existing_tags]
            
            return unique_tags[:10]  # ìµœëŒ€ 10ê°œ
        except:
            return []


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
llm_service = LLMService()
